{
  "name": "llm-chatter-server",
  "private": true,
  "version": "0.0.8",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "devDependencies": {
    "vite": "^6.2.0"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.39.0",
    "@google/generative-ai": "^0.23.0",
    "@openai/realtime-api-beta": "github:openai/openai-realtime-api-beta",
    "@tensorflow-models/universal-sentence-encoder": "^1.3.3",
    "@tensorflow/tfjs-converter": "^3.21.0",
    "@tensorflow/tfjs-core": "^3.21.0",
    "@tensorflow/tfjs-node": "^4.20.0",
    "axios": "^1.8.1",
    "bcryptjs": "^3.0.2",
    "body-parser": "^2.1.0",
    "chalk": "^5.4.1",
    "cheerio": "^1.0.0",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "express": "^5.0.1",
    "express-rate-limit": "^7.5.0",
    "express-validator": "^7.2.1",
    "fs": "^0.0.2",
    "jsonwebtoken": "^9.0.2",
    "langchain": "^0.0.168",
    "openai": "^4.86.1",
    "path": "^0.12.7",
    "strip-ansi": "^7.1.0",
    "ws": "^8.18.1"
  }
}
